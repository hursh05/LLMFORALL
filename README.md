# LLMFORALL ğŸš€  
A Full-Stack Retrieval-Augmented Generation (RAG) Application

LLMFORALL is a production-ready RAG system that allows users to upload documents (PDFs) and ask natural language questions.  
The system retrieves relevant content using vector search and generates accurate answers using a Large Language Model.

---

## ğŸ”¥ Features

- ğŸ“„ Upload and process multiple PDF documents
- ğŸ” Semantic search using vector embeddings
- ğŸ§  Context-aware question answering (RAG)
- âš¡ FastAPI backend
- â˜ï¸ Pinecone vector database
- ğŸ¤– Cohere embeddings + reranking
- ğŸ§  Groq LLM for fast inference
- ğŸ§© Modular & scalable architecture

---

## ğŸ—ï¸ Tech Stack

### Backend
- **Python 3.11**
- **FastAPI**
- **Cohere API** (Embeddings + Rerank)
- **Pinecone** (Vector Database)
- **Groq API** (LLM inference)
- **Langchain**

### Frontend
- **HTML**
- **CSS**
- **JavaScript (Fetch API)**

---

## ğŸ“‚ Project Structure

```text
LLMFORALL/
â”‚
â”œâ”€â”€ server/
â”‚   â”œâ”€â”€ main.py
â”‚   â”œâ”€â”€ routes/
â”‚   â”œâ”€â”€ modules/
â”‚   â”œâ”€â”€ templates/
â”‚   â””â”€â”€ static/
â”‚
â”‚
â”œâ”€â”€ .env
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
